#!/usr/bin/env python3
# rag-studio/backend/scripts/seed_data.py
"""
ì´ˆê¸° ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸

ê°œë°œ ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì´ˆê¸° ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

import asyncio
import sys
import uuid
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

from sqlalchemy.ext.asyncio import AsyncSession

from app.core.config import settings
from app.utils.logger import logger
from app.db.session import AsyncSessionLocal, engine
from app.db.base import Base
from app.models.user import User
from app.models.pipeline import Pipeline
from app.models.rag_config import PromptTemplate, LLMConfiguration, RAGConfiguration
from app.models.opensearch import IndexConfiguration, EmbeddingModel
from app.core.security import get_password_hash
from app.schemas.pipeline import PipelineType, PipelineStatus
from app.services.opensearch_service import OpenSearchService
from app.schemas.opensearch import DocumentInput


class DataSeeder:
    """ë°ì´í„° ì‹œë”© í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.opensearch_service = OpenSearchService()
        
    async def create_tables(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„±"""
        try:
            async with engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    async def create_users(self, db: AsyncSession) -> List[User]:
        """ì‚¬ìš©ì ë°ì´í„° ìƒì„±"""
        users_data = [
            {
                "email": "admin@ragstudio.com",
                "username": "admin",
                "full_name": "ì‹œìŠ¤í…œ ê´€ë¦¬ì",
                "password": "admin123!@#",
                "is_active": True,
                "is_superuser": True
            },
            {
                "email": "demo@ragstudio.com", 
                "username": "demo",
                "full_name": "ë°ëª¨ ì‚¬ìš©ì",
                "password": "demo123!@#",
                "is_active": True,
                "is_superuser": False
            },
            {
                "email": "test@ragstudio.com",
                "username": "test",
                "full_name": "í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì", 
                "password": "test123!@#",
                "is_active": True,
                "is_superuser": False
            }
        ]
        
        created_users = []
        
        for user_data in users_data:
            # ê¸°ì¡´ ì‚¬ìš©ì í™•ì¸
            result = await db.execute(
                db.query(User).filter(User.email == user_data["email"])
            )
            existing_user = result.scalar_one_or_none()
            
            if existing_user:
                logger.info(f"â„¹ï¸ ì‚¬ìš©ìê°€ ì´ë¯¸ ì¡´ì¬í•¨: {user_data['email']}")
                created_users.append(existing_user)
                continue
            
            # ìƒˆ ì‚¬ìš©ì ìƒì„±
            user = User(
                email=user_data["email"],
                username=user_data["username"],
                full_name=user_data["full_name"],
                hashed_password=get_password_hash(user_data["password"]),
                is_active=user_data["is_active"],
                is_superuser=user_data["is_superuser"]
            )
            
            db.add(user)
            created_users.append(user)
            logger.info(f"âœ… ì‚¬ìš©ì ìƒì„±: {user_data['email']}")
        
        await db.commit()
        
        # ì‚¬ìš©ì ì •ë³´ ìƒˆë¡œê³ ì¹¨
        for user in created_users:
            await db.refresh(user)
        
        return created_users
    
    async def create_embedding_models(self, db: AsyncSession) -> List[EmbeddingModel]:
        """ì„ë² ë”© ëª¨ë¸ ë°ì´í„° ìƒì„±"""
        models_data = [
            {
                "name": "OpenAI Text Embedding 3 Small",
                "provider": "openai",
                "model_id": "text-embedding-3-small",
                "dimension": 1536,
                "max_input_length": 8191,
                "is_active": True,
                "is_default": True,
                "description": "OpenAIì˜ ìµœì‹  ì„ë² ë”© ëª¨ë¸ (ì†Œí˜•)"
            },
            {
                "name": "Sentence Transformers All-MiniLM-L6-v2",
                "provider": "huggingface",
                "model_id": "sentence-transformers/all-MiniLM-L6-v2",
                "dimension": 384,
                "max_input_length": 256,
                "is_active": True,
                "is_default": False,
                "description": "ê²½ëŸ‰í™”ëœ ë‹¤êµ­ì–´ ì„ë² ë”© ëª¨ë¸"
            },
            {
                "name": "OpenAI Text Embedding Ada 002",
                "provider": "openai", 
                "model_id": "text-embedding-ada-002",
                "dimension": 1536,
                "max_input_length": 8191,
                "is_active": False,
                "is_default": False,
                "description": "OpenAIì˜ ì´ì „ ì„¸ëŒ€ ì„ë² ë”© ëª¨ë¸"
            }
        ]
        
        created_models = []
        
        for model_data in models_data:
            # ê¸°ì¡´ ëª¨ë¸ í™•ì¸
            result = await db.execute(
                db.query(EmbeddingModel).filter(EmbeddingModel.name == model_data["name"])
            )
            existing_model = result.scalar_one_or_none()
            
            if existing_model:
                logger.info(f"â„¹ï¸ ì„ë² ë”© ëª¨ë¸ì´ ì´ë¯¸ ì¡´ì¬í•¨: {model_data['name']}")
                created_models.append(existing_model)
                continue
            
            # ìƒˆ ëª¨ë¸ ìƒì„±
            model = EmbeddingModel(**model_data)
            db.add(model)
            created_models.append(model)
            logger.info(f"âœ… ì„ë² ë”© ëª¨ë¸ ìƒì„±: {model_data['name']}")
        
        await db.commit()
        
        for model in created_models:
            await db.refresh(model)
        
        return created_models
    
    async def create_prompt_templates(self, db: AsyncSession, admin_user: User) -> List[PromptTemplate]:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±"""
        templates_data = [
            {
                "name": "ê¸°ë³¸ QA í”„ë¡¬í”„íŠ¸",
                "description": "ì¼ë°˜ì ì¸ ì§ˆì˜ì‘ë‹µì„ ìœ„í•œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸",
                "template_text": """ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

ë¬¸ë§¥:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€: ë¬¸ë§¥ì— ê¸°ë°˜í•˜ì—¬ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤.""",
                "template_format": "f-string",
                "variables": [
                    {"name": "context", "type": "string", "required": True},
                    {"name": "question", "type": "string", "required": True}
                ],
                "category": "qa",
                "use_case": "naive_rag",
                "is_active": True,
                "is_default": True
            },
            {
                "name": "ë¶„ì„ì  ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸",
                "description": "ë³µì¡í•œ ë¶„ì„ì´ í•„ìš”í•œ ì§ˆë¬¸ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸",
                "template_text": """ì œê³µëœ ë¬¸ì„œë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ê´€ë ¨ ë¬¸ì„œë“¤:
{context}

ì§ˆë¬¸: {question}

ë¶„ì„ ì§€ì¹¨:
1. ì—¬ëŸ¬ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ë¶„ì„
2. ê·¼ê±°ì™€ í•¨ê»˜ ë…¼ë¦¬ì  ê²°ë¡  ì œì‹œ
3. ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ ëª…ì‹œ

ë¶„ì„ ê²°ê³¼:""",
                "template_format": "f-string",
                "variables": [
                    {"name": "context", "type": "string", "required": True},
                    {"name": "question", "type": "string", "required": True}
                ],
                "category": "analysis",
                "use_case": "graph_rag",
                "is_active": True,
                "is_default": False
            },
            {
                "name": "ìš”ì•½ í”„ë¡¬í”„íŠ¸",
                "description": "ë¬¸ì„œ ìš”ì•½ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸",
                "template_text": """ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì£¼ì„¸ìš”.

ë¬¸ì„œ ë‚´ìš©:
{content}

ìš”ì•½ ìš”êµ¬ì‚¬í•­:
- í•µì‹¬ ë‚´ìš©ì„ 3-5ê°œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½
- ì¤‘ìš”í•œ í‚¤ì›Œë“œ í¬í•¨
- ê°ê´€ì ì´ê³  ì •í™•í•œ ìš”ì•½

ìš”ì•½:""",
                "template_format": "f-string",
                "variables": [
                    {"name": "content", "type": "string", "required": True}
                ],
                "category": "summarization",
                "use_case": "naive_rag",
                "is_active": True,
                "is_default": False
            }
        ]
        
        created_templates = []
        
        for template_data in templates_data:
            # ê¸°ì¡´ í…œí”Œë¦¿ í™•ì¸
            result = await db.execute(
                db.query(PromptTemplate).filter(PromptTemplate.name == template_data["name"])
            )
            existing_template = result.scalar_one_or_none()
            
            if existing_template:
                logger.info(f"â„¹ï¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì´ ì´ë¯¸ ì¡´ì¬í•¨: {template_data['name']}")
                created_templates.append(existing_template)
                continue
            
            # ìƒˆ í…œí”Œë¦¿ ìƒì„±
            template = PromptTemplate(
                **template_data,
                created_by=admin_user.id
            )
            db.add(template)
            created_templates.append(template)
            logger.info(f"âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±: {template_data['name']}")
        
        await db.commit()
        
        for template in created_templates:
            await db.refresh(template)
        
        return created_templates
    
    async def create_llm_configurations(self, db: AsyncSession, admin_user: User) -> List[LLMConfiguration]:
        """LLM ì„¤ì • ìƒì„±"""
        configs_data = [
            {
                "name": "GPT-4 Turbo",
                "provider": "openai",
                "model_name": "gpt-4-turbo-preview",
                "temperature": 0.7,
                "max_tokens": 2000,
                "description": "OpenAI GPT-4 Turbo ëª¨ë¸",
                "is_active": True,
                "is_default": True
            },
            {
                "name": "GPT-3.5 Turbo",
                "provider": "openai", 
                "model_name": "gpt-3.5-turbo",
                "temperature": 0.7,
                "max_tokens": 1500,
                "description": "OpenAI GPT-3.5 Turbo ëª¨ë¸",
                "is_active": True,
                "is_default": False
            },
            {
                "name": "Conservative GPT-4",
                "provider": "openai",
                "model_name": "gpt-4-turbo-preview",
                "temperature": 0.3,
                "max_tokens": 2000,
                "description": "ë³´ìˆ˜ì ì¸ ì„¤ì •ì˜ GPT-4 ëª¨ë¸",
                "is_active": True,
                "is_default": False
            }
        ]
        
        created_configs = []
        
        for config_data in configs_data:
            # ê¸°ì¡´ ì„¤ì • í™•ì¸
            result = await db.execute(
                db.query(LLMConfiguration).filter(LLMConfiguration.name == config_data["name"])
            )
            existing_config = result.scalar_one_or_none()
            
            if existing_config:
                logger.info(f"â„¹ï¸ LLM ì„¤ì •ì´ ì´ë¯¸ ì¡´ì¬í•¨: {config_data['name']}")
                created_configs.append(existing_config)
                continue
            
            # ìƒˆ ì„¤ì • ìƒì„±
            config = LLMConfiguration(
                **config_data,
                created_by=admin_user.id
            )
            db.add(config)
            created_configs.append(config)
            logger.info(f"âœ… LLM ì„¤ì • ìƒì„±: {config_data['name']}")
        
        await db.commit()
        
        for config in created_configs:
            await db.refresh(config)
        
        return created_configs
    
    async def create_index_configurations(self, db: AsyncSession, admin_user: User) -> List[IndexConfiguration]:
        """ì¸ë±ìŠ¤ ì„¤ì • ìƒì„±"""
        configs_data = [
            {
                "name": "rag-documents",
                "description": "ê¸°ë³¸ RAG ë¬¸ì„œ ì¸ë±ìŠ¤",
                "number_of_shards": 2,
                "number_of_replicas": 1,
                "embedding_dimension": 384,
                "is_active": True,
                "index_created": True
            },
            {
                "name": "rag-test",
                "description": "í…ŒìŠ¤íŠ¸ìš© ì¸ë±ìŠ¤",
                "number_of_shards": 1,
                "number_of_replicas": 0,
                "embedding_dimension": 384,
                "is_active": True,
                "index_created": True
            },
            {
                "name": "rag-benchmark",
                "description": "ë²¤ì¹˜ë§ˆí¬ìš© ì¸ë±ìŠ¤",
                "number_of_shards": 1,
                "number_of_replicas": 1,
                "embedding_dimension": 768,
                "is_active": True,
                "index_created": True
            }
        ]
        
        created_configs = []
        
        for config_data in configs_data:
            # ê¸°ì¡´ ì„¤ì • í™•ì¸
            result = await db.execute(
                db.query(IndexConfiguration).filter(IndexConfiguration.name == config_data["name"])
            )
            existing_config = result.scalar_one_or_none()
            
            if existing_config:
                logger.info(f"â„¹ï¸ ì¸ë±ìŠ¤ ì„¤ì •ì´ ì´ë¯¸ ì¡´ì¬í•¨: {config_data['name']}")
                created_configs.append(existing_config)
                continue
            
            # ìƒˆ ì„¤ì • ìƒì„±
            config = IndexConfiguration(
                **config_data,
                created_by=admin_user.id
            )
            db.add(config)
            created_configs.append(config)
            logger.info(f"âœ… ì¸ë±ìŠ¤ ì„¤ì • ìƒì„±: {config_data['name']}")
        
        await db.commit()
        
        for config in created_configs:
            await db.refresh(config)
        
        return created_configs
    
    async def create_pipelines(self, db: AsyncSession, admin_user: User) -> List[Pipeline]:
        """íŒŒì´í”„ë¼ì¸ ìƒì„±"""
        pipelines_data = [
            {
                "name": "ê¸°ë³¸ QA íŒŒì´í”„ë¼ì¸",
                "description": "ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µì„ ìœ„í•œ ê¸°ë³¸ íŒŒì´í”„ë¼ì¸",
                "pipeline_type": PipelineType.NAIVE_RAG,
                "status": PipelineStatus.INACTIVE,
                "index_name": "rag-documents",
                "config": {
                    "retrieval_top_k": 5,
                    "temperature": 0.7,
                    "max_tokens": 2000,
                    "search_filters": {}
                }
            },
            {
                "name": "ê³ ê¸‰ ë¶„ì„ íŒŒì´í”„ë¼ì¸",
                "description": "ë³µì¡í•œ ë¶„ì„ì„ ìœ„í•œ Graph RAG íŒŒì´í”„ë¼ì¸",
                "pipeline_type": PipelineType.GRAPH_RAG,
                "status": PipelineStatus.INACTIVE,
                "index_name": "rag-documents",
                "config": {
                    "retrieval_top_k": 10,
                    "temperature": 0.5,
                    "max_tokens": 3000,
                    "use_llm_filtering": True,
                    "max_context_docs": 7
                }
            },
            {
                "name": "í…ŒìŠ¤íŠ¸ íŒŒì´í”„ë¼ì¸",
                "description": "ê°œë°œ ë° í…ŒìŠ¤íŠ¸ìš© íŒŒì´í”„ë¼ì¸",
                "pipeline_type": PipelineType.NAIVE_RAG,
                "status": PipelineStatus.INACTIVE,
                "index_name": "rag-test",
                "config": {
                    "retrieval_top_k": 3,
                    "temperature": 0.8,
                    "max_tokens": 1500,
                    "search_filters": {}
                }
            }
        ]
        
        created_pipelines = []
        
        for pipeline_data in pipelines_data:
            # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í™•ì¸
            result = await db.execute(
                db.query(Pipeline).filter(Pipeline.name == pipeline_data["name"])
            )
            existing_pipeline = result.scalar_one_or_none()
            
            if existing_pipeline:
                logger.info(f"â„¹ï¸ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì¡´ì¬í•¨: {pipeline_data['name']}")
                created_pipelines.append(existing_pipeline)
                continue
            
            # ìƒˆ íŒŒì´í”„ë¼ì¸ ìƒì„±
            pipeline = Pipeline(
                **pipeline_data,
                created_by=admin_user.id
            )
            db.add(pipeline)
            created_pipelines.append(pipeline)
            logger.info(f"âœ… íŒŒì´í”„ë¼ì¸ ìƒì„±: {pipeline_data['name']}")
        
        await db.commit()
        
        for pipeline in created_pipelines:
            await db.refresh(pipeline)
        
        return created_pipelines
    
    async def create_sample_documents(self) -> bool:
        """ìƒ˜í”Œ ë¬¸ì„œ ìƒì„±"""
        try:
            sample_docs = [
                DocumentInput(
                    document_id="doc_ai_basics_001",
                    title="ì¸ê³µì§€ëŠ¥ ê¸°ì´ˆ ê°œë…",
                    content="""
                    ì¸ê³µì§€ëŠ¥(AI)ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ì—¬ í•™ìŠµ, ì¶”ë¡ , ì¸ì‹ ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
                    ê¸°ê³„í•™ìŠµì€ AIì˜ í•˜ìœ„ ë¶„ì•¼ë¡œ, ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡ì´ë‚˜ ê²°ì •ì„ ë‚´ë¦½ë‹ˆë‹¤.
                    ë”¥ëŸ¬ë‹ì€ ì‹ ê²½ë§ì„ ì‚¬ìš©í•œ ê¸°ê³„í•™ìŠµì˜ í•œ ë°©ë²•ìœ¼ë¡œ, ë³µì¡í•œ íŒ¨í„´ ì¸ì‹ì— íƒì›”í•©ë‹ˆë‹¤.
                    ìì—°ì–´ì²˜ë¦¬(NLP)ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” AI ë¶„ì•¼ì…ë‹ˆë‹¤.
                    """,
                    source="seed",
                    metadata={"category": "ai_basics", "difficulty": "beginner"}
                ),
                DocumentInput(
                    document_id="doc_rag_system_001",
                    title="RAG ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
                    content="""
                    RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì€ ê²€ìƒ‰ê³¼ ìƒì„±ì„ ê²°í•©í•œ AI ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.
                    ë¬¸ì„œ ì €ì¥ì†Œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ LLMì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
                    ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ë¬¸ì„œë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì˜ë¯¸ì  ê²€ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
                    OpenSearch, Pinecone, Weaviate ë“±ì´ ë²¡í„° ê²€ìƒ‰ì„ ì§€ì›í•˜ëŠ” ëŒ€í‘œì ì¸ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.
                    """,
                    source="seed",
                    metadata={"category": "rag_system", "difficulty": "intermediate"}
                ),
                DocumentInput(
                    document_id="doc_llm_models_001",
                    title="ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM) ì¢…ë¥˜",
                    content="""
                    GPT(Generative Pre-trained Transformer) ì‹œë¦¬ì¦ˆëŠ” OpenAIì—ì„œ ê°œë°œí•œ ëŒ€í‘œì ì¸ LLMì…ë‹ˆë‹¤.
                    ClaudeëŠ” Anthropicì—ì„œ ê°œë°œí•œ ì•ˆì „ì„±ì— ì¤‘ì ì„ ë‘” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
                    LLaMAëŠ” Metaì—ì„œ ê°œë°œí•œ ì˜¤í”ˆì†ŒìŠ¤ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.
                    PaLMì€ Googleì—ì„œ ê°œë°œí•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.
                    ê° ëª¨ë¸ì€ ê³ ìœ í•œ íŠ¹ì„±ê³¼ ì„±ëŠ¥ì„ ê°€ì§€ê³  ìˆì–´ ìš©ë„ì— ë”°ë¼ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.
                    """,
                    source="seed",
                    metadata={"category": "llm_models", "difficulty": "intermediate"}
                ),
                DocumentInput(
                    document_id="doc_embedding_001",
                    title="í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ ë²¡í„° ê²€ìƒ‰",
                    content="""
                    í…ìŠ¤íŠ¸ ì„ë² ë”©ì€ í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ë²¡í„° ê³µê°„ì˜ ì ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.
                    Word2Vec, GloVe, FastTextëŠ” ì „í†µì ì¸ ì„ë² ë”© ê¸°ë²•ì…ë‹ˆë‹¤.
                    BERT, RoBERTa, Sentence-BERTëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ í˜„ëŒ€ì  ì„ë² ë”© ëª¨ë¸ì…ë‹ˆë‹¤.
                    ì½”ì‚¬ì¸ ìœ ì‚¬ë„, ìœ í´ë¦¬ë“œ ê±°ë¦¬, ë‚´ì  ë“±ì´ ë²¡í„° ê°„ ìœ ì‚¬ë„ ì¸¡ì •ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
                    HNSW, LSH ë“±ì˜ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëŒ€ê·œëª¨ ë²¡í„° ê²€ìƒ‰ì„ íš¨ìœ¨í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    """,
                    source="seed",
                    metadata={"category": "embedding", "difficulty": "advanced"}
                ),
                DocumentInput(
                    document_id="doc_prompt_engineering_001",
                    title="í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•",
                    content="""
                    í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì€ AI ëª¨ë¸ì—ì„œ ì›í•˜ëŠ” ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ì…ë ¥ì„ ìµœì í™”í•˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.
                    Few-shot í”„ë¡¬í”„íŒ…ì€ ëª‡ ê°œì˜ ì˜ˆì‹œë¥¼ ì œê³µí•˜ì—¬ ëª¨ë¸ì´ íŒ¨í„´ì„ í•™ìŠµí•˜ê²Œ í•©ë‹ˆë‹¤.
                    Chain-of-ThoughtëŠ” ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ì„ ëª…ì‹œí•˜ì—¬ ë³µì¡í•œ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
                    Role-playingì€ ëª¨ë¸ì—ê²Œ íŠ¹ì • ì—­í• ì„ ë¶€ì—¬í•˜ì—¬ í•´ë‹¹ ê´€ì ì—ì„œ ë‹µë³€í•˜ê²Œ í•©ë‹ˆë‹¤.
                    Temperature, Top-p ë“±ì˜ íŒŒë¼ë¯¸í„°ë¡œ ìƒì„± ê²°ê³¼ì˜ ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì„ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    """,
                    source="seed",
                    metadata={"category": "prompt_engineering", "difficulty": "intermediate"}
                )
            ]
            
            # ë¬¸ì„œ ìƒ‰ì¸
            result = await self.opensearch_service.index_documents(
                "rag-documents", 
                sample_docs
            )
            
            if result["successful"] > 0:
                logger.info(f"âœ… ìƒ˜í”Œ ë¬¸ì„œ ìƒ‰ì¸ ì™„ë£Œ: {result['successful']}ê°œ")
                return True
            else:
                logger.error(f"âŒ ìƒ˜í”Œ ë¬¸ì„œ ìƒ‰ì¸ ì‹¤íŒ¨: {result}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ìƒ˜í”Œ ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False


async def main():
    """ë©”ì¸ ì‹œë”© í•¨ìˆ˜"""
    logger.info("ğŸŒ± ì´ˆê¸° ë°ì´í„° ìƒì„± ì‹œì‘")
    
    seeder = DataSeeder()
    
    try:
        # 1. í…Œì´ë¸” ìƒì„±
        await seeder.create_tables()
        
        # 2. ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        async with AsyncSessionLocal() as db:
            # 3. ì‚¬ìš©ì ìƒì„±
            users = await seeder.create_users(db)
            admin_user = next(u for u in users if u.is_superuser)
            
            # 4. ì„ë² ë”© ëª¨ë¸ ìƒì„±
            await seeder.create_embedding_models(db, admin_user)
            
            # 5. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒì„±
            await seeder.create_prompt_templates(db, admin_user)
            
            # 6. LLM ì„¤ì • ìƒì„±
            await seeder.create_llm_configurations(db, admin_user)
            
            # 7. ì¸ë±ìŠ¤ ì„¤ì • ìƒì„±
            await seeder.create_index_configurations(db, admin_user)
            
            # 8. íŒŒì´í”„ë¼ì¸ ìƒì„±
            await seeder.create_pipelines(db, admin_user)
        
        # 9. OpenSearch ìƒ˜í”Œ ë¬¸ì„œ ìƒì„±
        await seeder.create_sample_documents()
        
        logger.info("ğŸ‰ ì´ˆê¸° ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        return True
        
    except Exception as e:
        logger.error(f"ğŸ’¥ ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False
    finally:
        await seeder.opensearch_service.close()


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ì´ˆê¸° ë°ì´í„° ìƒì„±")
    parser.add_argument(
        "--skip-documents",
        action="store_true",
        help="ë¬¸ì„œ ìƒì„± ê±´ë„ˆë›°ê¸°"
    )
    
    args = parser.parse_args()
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    success = asyncio.run(main())
    
    if success:
        print("\nâœ… ì´ˆê¸° ë°ì´í„° ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“‹ ìƒì„±ëœ ë°ì´í„°:")
        print("  ğŸ‘¥ ì‚¬ìš©ì: admin, demo, test")
        print("  ğŸ”§ íŒŒì´í”„ë¼ì¸: ê¸°ë³¸ QA, ê³ ê¸‰ ë¶„ì„, í…ŒìŠ¤íŠ¸")
        print("  ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ: AI ê¸°ì´ˆ, RAG ì‹œìŠ¤í…œ, LLM ëª¨ë¸ ë“±")
        print("  âš™ï¸ ì„¤ì •: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿, LLM ì„¤ì •, ì¸ë±ìŠ¤ ì„¤ì •")
        print("\nğŸ”‘ ê¸°ë³¸ ë¡œê·¸ì¸ ì •ë³´:")
        print("  ê´€ë¦¬ì: admin@ragstudio.com / admin123!@#")
        print("  ë°ëª¨: demo@ragstudio.com / demo123!@#")
        sys.exit(0)
    else:
        print("\nâŒ ì´ˆê¸° ë°ì´í„° ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤!")
        sys.exit(1)